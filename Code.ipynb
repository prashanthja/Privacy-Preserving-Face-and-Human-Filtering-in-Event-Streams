{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9BGMA9aspMZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import numpy as np\n",
        "import dgl\n",
        "import networkx as nx\n",
        "\n",
        "E = set([(x, y) for x in range(10) for y in range(10)])\n",
        "Tx = 2  # Spatial threshold for neighbors\n",
        "sigma = 0.5  # Temporal scaling factor\n",
        "Tt = 5  # Temporal threshold for noise generation\n",
        "\n",
        "# Step 1: Mask Generation using a simple DNN\n",
        "class MaskGenerator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MaskGenerator, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.sigmoid(self.fc3(x))  # Output between 0 and 1 (for masking)\n",
        "        return x\n",
        "\n",
        "# Step 2: Spatial Neighbor Detection using Graph Neural Network (GNN)\n",
        "class GNNSpatialNeighbor(nn.Module):\n",
        "    def __init__(self, in_feats, hidden_feats, out_feats):\n",
        "        super(GNNSpatialNeighbor, self).__init__()\n",
        "        self.conv1 = dgl.nn.GraphConv(in_feats, hidden_feats)\n",
        "        self.conv2 = dgl.nn.GraphConv(hidden_feats, out_feats)\n",
        "\n",
        "    def forward(self, graph, features):\n",
        "        h = self.conv1(graph, features)\n",
        "        h = torch.relu(h)\n",
        "        h = self.conv2(graph, h)\n",
        "        return h\n",
        "\n",
        "# Step 3: Noise Generation using GAN\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)  # Output synthetic noise event coordinates\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.sigmoid(self.fc3(x))  # Output probability of being real or fake\n",
        "        return x\n",
        "\n",
        "# Step 4: Polarity Mapping (XOR-based mapping)\n",
        "def lambda_mapping(E_tilde, key):\n",
        "    # Flip the polarity based on XOR with a Szudzik pairing function and key\n",
        "    return [(x, y, p ^ (key % 2)) for (x, y, p) in E_tilde]\n",
        "\n",
        "# Step 5: Simulated Main Algorithm with Deep Learning\n",
        "\n",
        "def main_algorithm(E, Tx, sigma, Tt):\n",
        "    # 1. Initialize mask M (using a simple neural network for this demo)\n",
        "    Ex = set(random.sample(E, 10))  # Initial subset of events Ex\n",
        "    M = E - Ex  # Mask M, which is disjoint from Ex\n",
        "\n",
        "    mask_gen_model = MaskGenerator()\n",
        "    optimizer = optim.Adam(mask_gen_model.parameters(), lr=0.001)\n",
        "\n",
        "    # For each event in Ex, find spatial neighbors R\n",
        "    for xi in Ex:\n",
        "        x, y = xi\n",
        "        # For demo, convert the coordinates (x, y) into a tensor for prediction\n",
        "        xi_tensor = torch.tensor([[x, y]], dtype=torch.float32)\n",
        "        mask_prob = mask_gen_model(xi_tensor).item()\n",
        "\n",
        "        # Create a mask based on the output probability\n",
        "        if mask_prob > 0.5:  # Simple threshold to simulate \"masking\"\n",
        "            M.add(xi)\n",
        "\n",
        "    print(f\"Mask M: {M}\")\n",
        "\n",
        "    # 2. Spatial Neighbor Detection with GNN (dummy graph and features for this demo)\n",
        "    G = nx.grid_2d_graph(10, 10)  # Create a graph of 10x10 grid\n",
        "    g = dgl.from_networkx(G)  # Convert to DGL graph\n",
        "    features = torch.randn((g.num_nodes(), 2))  # Random features for nodes\n",
        "\n",
        "    gnn_model = GNNSpatialNeighbor(2, 32, 1)  # Example GNN model\n",
        "    gnn_output = gnn_model(g, features)\n",
        "\n",
        "    print(f\"GNN Output (Neighbors): {gnn_output}\")\n",
        "\n",
        "    # 3. Noise Generation using GAN (simplified)\n",
        "    noise_gen = Generator()\n",
        "    noise_disc = Discriminator()\n",
        "\n",
        "    # Training GAN for noise generation\n",
        "    optimizer_g = optim.Adam(noise_gen.parameters(), lr=0.001)\n",
        "    optimizer_d = optim.Adam(noise_disc.parameters(), lr=0.001)\n",
        "\n",
        "    real_events = torch.randn(10, 2)  # Real events in the event space\n",
        "    fake_events = noise_gen(torch.randn(10, 2))  # Generated noise events\n",
        "\n",
        "    # Discriminator loss\n",
        "    real_preds = noise_disc(real_events)\n",
        "    fake_preds = noise_disc(fake_events)\n",
        "    loss_d = -torch.mean(torch.log(real_preds) + torch.log(1 - fake_preds))\n",
        "\n",
        "    # Generator loss\n",
        "    fake_preds = noise_disc(fake_events)\n",
        "    loss_g = -torch.mean(torch.log(fake_preds))\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer_d.zero_grad()\n",
        "    loss_d.backward()\n",
        "    optimizer_d.step()\n",
        "\n",
        "    optimizer_g.zero_grad()\n",
        "    loss_g.backward()\n",
        "    optimizer_g.step()\n",
        "\n",
        "    print(f\"Generator Loss: {loss_g.item()}, Discriminator Loss: {loss_d.item()}\")\n",
        "\n",
        "    # 4. Polarity Mapping (XOR-based)\n",
        "    E_tilde = [(x, y, random.choice([0, 1])) for x, y in E]  # Simulate encrypted events\n",
        "    key = random.randint(0, 1000)\n",
        "    E_tilde = lambda_mapping(E_tilde, key)\n",
        "\n",
        "    print(f\"Encrypted Event Stream: {E_tilde}\")\n",
        "    return E_tilde\n",
        "\n",
        "# Run the main algorithm\n",
        "E_tilde = main_algorithm(E, Tx, sigma, Tt)\n"
      ]
    }
  ]
}